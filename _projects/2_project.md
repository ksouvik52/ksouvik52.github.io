---
layout: page
title: LLM Personalization and Long-context Learning
description: Efficient fine-tuning and long-context understanding
img: assets/img/lora.jpg
importance: 2
category: work
related_publications: false
---

<p>
This research thrust focuses on enabling personalization of foundation models through memory efficient fine-tuning solutions. Some of the research outcome of this project includes: <a target="_blank" href="https://arxiv.org/pdf/2406.12832v1"><b>LaMDA</b></a>, <a target="_blank" href="https://aclanthology.org/2024.acl-short.16/"><b>AFLoRA</b></a>, efficient long-context understanding without forgeting in the middle. 
</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/lamda.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/clampvit.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/long_context.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    We explore different avenues for memory efficient finetuning. Additionally, we explore efficient deployability on long-context understanding tasks of LLMs.
</div>

