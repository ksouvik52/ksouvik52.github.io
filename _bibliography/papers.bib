---
---

@string{aps = {American Physical Society,}}

@inproceedings{you2024shiftaddllm,
  abbr={NeurIPS 2024},
  title={ShiftAddLLM: Accelerating Pretrained LLMs via Post-Training Multiplication-Less Reparameterization},
  author={You, Haoran and Guo, Yipin and Fu, Yichao and Zhou, Wei and Shi, Huihong and Zhang, Xiaofan and Kundu, Souvik and Yazdanbakhsh, Amir and Lin, Yingyan},
  journal="Thirty-Eighth Annual Conference on Neural Information Processing Systems",
  year="2024",
  code={https://github.com/GATECH-EIC/ShiftAddLLM?tab=readme-ov-file},
  pdf={https://arxiv.org/pdf/2406.05981}
}

@inproceedings{kang2024gear,
  title={GEAR: An efficient kv cache compression recipefor near-lossless generative inference of llm},
  author={Kang, Hao and Zhang, Qingru and Kundu, Souvik and Jeong, Geonhwa and Liu, Zaoxing and Krishna, Tushar and Zhao, Tuo},
  journal={(Spotlight) Thirty-Eighth Annual Conference on Neural Information Processing Systems Workshop},
  year={2024},
  code={https://github.com/opengear-project/GEAR},
  pdf={https://arxiv.org/pdf/2403.05527}
}

@inproceedings{azizi2024lamda,
  abbr={EMNLP 2024},
  title={LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation},
  author={Azizi, Seyedarmin and Kundu, Souvik and Pedram, Massoud},
  journal={Conference on Empirical Methods in Natural Language Processing (Findings)},
  year={2024},
  code={https://github.com/ArminAzizi98/LaMDA},
  pdf={https://arxiv.org/pdf/2406.12832v1}
}

@inproceedings{ramachandran2024clamp,
  abbr={EMNLP 2024},
  title={CLAMP-ViT: contrastive data-free learning for adaptive post-training quantization of ViTs},
  author={Ramachandran, Akshat and Kundu, Souvik and Krishna, Tushar},
  journal={European Conference on Computer Vision},
  year={2024},
  code={https://github.com/georgia-tech-synergy-lab/CLAMP-ViT/tree/main},
  pdf={https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08434.pdf}
}

@inproceedings{li2023stableq,
  title={GenQ: Quantization in Low Data Regimes with Generative Synthetic Data},
  author={Li, Yuhang and Kim, Youngeun and Lee, Donghyun and Panda, Priyadarshini},
  journal={European Conference on Computer Vision},
  year={2024},
  pdf={https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/02058.pdf}
}

@inproceedings{liu2024aflora,
  abbr={ACL 2024},
  title={AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models},
  author={Kundu*, Souvik and Liu*, Zeyu and Li, Anni and Wan, Junrui and Jiang, Lianghao and Beerel, Peter Anthony},
  journal={(Best paper recommendation) Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics},
  year={2024},
  code={https://github.com/georgia-tech-synergy-lab/CLAMP-ViT/tree/main},
  pdf={https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08434.pdf}
}

@inproceedings{yin2023junk,
  abbr={ICML 2024},
  title={Junk dna hypothesis: A task-centric angle of llm pre-trained weights through sparsity},
  author={Yin, Lu and Liu, Shiwei and Jaiswal, Ajay and Kundu, Souvik and Wang, Zhangyang},
  journal={International Conference on Machine Learning},
  year={2024}
}

@inproceedings{kundubit,
  abbr={TMLR 2024},
  title={Bit-by-Bit: Investigating the Vulnerabilities of Binary Neural Networks to Adversarial Bit Flipping},
  author={Kundu, Shamik and Das, Sanjay and Karmakar, Sayar and Raha, Arnab and Kundu, Souvik and Makris, Yiorgos and Basu, Kanad},
  journal={Transactions on Machine Learning Research},
  year={2024}
}

@inproceedings{zhoumakes,
  abbr={ICPR 2024},
  title={What Makes Vision Transformers Robust Towards Bit-Flip Attacks?},
  author={Zhou, Xuan and Kundu, Souvik and Chen, Dake and Huang, Jie and Beerel, Peter},
  journal={(Oral) International Conference on Pattern Recognition},
  year={2024}
}

@inproceedings{sarkar2024block,
  abbr={CVPR 2024},
  title={Block Selective Reprogramming for On-device Training of Vision Transformers},
  author={Sarkar, Sreetama and Kundu, Souvik and Zheng, Kai and Beerel, Peter A},
  journal={(Oral) Workshop Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognitio},
  year={2024}
}

@inproceedings{sarkar2024rlnet,
  title={RLNet: Robust Linearized Networks for Efficient Private Inference},
  author={Kundu*, Souvik and Sarkar*, Sreetama and Beerel, Peter A},
  booktitle={(Oral) Workshop Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@inproceedings{chen2024dia,
  title={DIA: Diffusion based Inverse Network Attack on Collaborative Inference},
  author={Chen, Dake and Li, Shiduo and Zhang, Yuke and Li, Chenghao and Kundu, Souvik and Beerel, Peter A},
  booktitle={Workshop Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@inproceedings{wang2023fusing,
  abbr={ICLR 2024},
  title={Fusing models with complementary expertise},
  author={Wang, Hongyi and Polo, Felipe Maia and Sun, Yuekai and Kundu, Souvik and Xing, Eric and Yurochkin, Mikhail},
  journal={International Conference on Learning Representation},
  year={2024}
}

@inproceedings{kundu2023sensi,
  abbr={ICASSP 2024},
  title={Sensi-BERT: Towards sensitivity driven fine-tuning for parameter-efficient bert},
  author={Kundu, Souvik and Sridhar, Sharath Nittur and Szankin, Maciej and Sundaresan, Sairam},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  year={2024}
}

@inproceedings{kundu2024recent,
  title={Recent Advances in Scalable Energy-Efficient and Trustworthy Spiking Neural Networks: from Algorithms to Technology},
  author={Kundu, Souvik and Zhu, Rui-Jie and Jaiswal, Akhilesh and Beerel, Peter A},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  year={2024},
}

@inproceedings{hoang2023don,
  abbr={NeurIPS 2023},
  title={Donâ€™t just prune by magnitude! Your mask topology is a secret weapon},
  author={Hoang, Duc and Kundu, Souvik and Liu, Shiwei and Wang, Zhangyang and others},
  journal={Advances in neural information processing systems},
  year={2023}
}

@inproceedings{chen2023rna,
  abbr={ICCAD 2023},
  title={RNA-ViT: Reduced-Dimension Approximate Normalized Attention Vision Transformers for Latency Efficient Private Inference},
  author={Kundu*, Souvik and Chen*, Dake and Zhang*, Yuke and Li, Chenghao and Beerel, Peter A},
  booktitle={International Conference on Computer Aided Design},
  year={2023},
}

@inproceedings{han2023vision,
  abbr={ICCV 2023},
  title={Vision HGNN: An image is more than a graph of nodes},
  author={Han, Yan and Wang, Peihao and Kundu, Souvik and Ding, Ying and Wang, Zhangyang},
  booktitle={(Oral) Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}

@inproceedings{zhang2023sal,
  title={SAL-ViT: Towards latency efficient private inference on vit using selective attention search with a learnable softmax approximation},
  author={Kundu*, Souvik and Zhang*, Yuke and Chen*, Dake and Li, Chenghao and Beerel, Peter A},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}

@inproceedings{sridhar2023instatune,
  title={Instatune: Instantaneous neural architecture search during fine-tuning},
  author={Sridhar, Sharath Nittur and Kundu, Souvik and Sundaresan, Sairam and Szankin, Maciej and Sarah, Anthony},
  booktitle={Workshop Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}

